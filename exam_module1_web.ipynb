{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y67ZHXu_wyry",
        "outputId": "aef2c279-66fc-46dc-ed37-972ad6347201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKh9npOlwsjD",
        "outputId": "5478f38c-d7de-4702-c013-6d59769fb16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-16 18:39:50.215 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.582 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-12-16 18:39:50.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.640 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.649 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.651 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.718 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.752 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.754 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.767 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-16 18:39:50.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "\n",
        "\n",
        "# Інтерфейс Streamlit\n",
        "st.title(\"Експериментування з параметрами моделі\")\n",
        "st.write(\"Змініть параметри моделі та запустіть тренування.\")\n",
        "\n",
        "# Параметри моделі\n",
        "units = st.slider(\"Кількість LSTM-юнітів\", min_value=16, max_value=256, step=16, value=64)\n",
        "embedding_dim = st.slider(\"Розмір вбудовування (embedding_dim)\", min_value=16, max_value=256, step=16, value=64)\n",
        "maxlen = st.slider(\"Максимальна довжина тексту (maxlen)\", min_value=50, max_value=500, step=50, value=100)\n",
        "epochs = st.slider(\"Кількість епох (epochs)\", min_value=1, max_value=20, step=1, value=5)\n",
        "batch_size = st.slider(\"Розмір пакету (batch_size)\", min_value=16, max_value=128, step=16, value=32)\n",
        "\n",
        "# Кнопка запуску навчання\n",
        "if st.button(\"Запустити навчання\"):\n",
        "    st.write(\"Тренування моделі...\")\n",
        "    accuracy, fig = train_model(units, embedding_dim, maxlen, epochs, batch_size)\n",
        "    st.write(f\"Точність на тестовому наборі: {accuracy:.4f}\")\n",
        "    st.pyplot(fig)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Сохраните скрипт Streamlit\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write('''import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import joblib\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    # Загрузка данных\n",
        "    file_path = '/content/drive/MyDrive/spam2.csv'\n",
        "    df = pd.read_csv(file_path, encoding='latin1')\n",
        "\n",
        "    # Очистка данных\n",
        "    df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "    df = df.rename(columns={'v1': 'label', 'v2': 'text'})\n",
        "\n",
        "    # Кодирование меток\n",
        "    le = LabelEncoder()\n",
        "    df['label'] = le.fit_transform(df['label'])\n",
        "\n",
        "    # Разделение данных\n",
        "    X = df['text']\n",
        "    y = df['label']\n",
        "\n",
        "    # Разделение на train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def prepare_sequences(X_train, X_test, maxlen=100, num_words=5000):\n",
        "    # Токенизация\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "    # Сохранение токенизатора\n",
        "    joblib.dump(tokenizer, 'tokenizer.joblib')\n",
        "\n",
        "    # Преобразование в последовательности\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "    # Паддинг\n",
        "    X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post', truncating='post')\n",
        "    X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "    return X_train_pad, X_test_pad\n",
        "\n",
        "def train_model(X_train_pad, y_train, X_test_pad, y_test, units=64, embedding_dim=64, maxlen=100, epochs=5, batch_size=32):\n",
        "    # Создание модели с параметрами\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=5000, output_dim=embedding_dim, input_length=maxlen),\n",
        "        layers.LSTM(units, return_sequences=True),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Компиляция модели\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Обучение модели\n",
        "    history = model.fit(\n",
        "        X_train_pad, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Оценка модели\n",
        "    loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
        "\n",
        "    # Сохранение модели\n",
        "    model.save('spam_classification_model.h5')\n",
        "\n",
        "    # Построение графика точности\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    return accuracy, plt\n",
        "\n",
        "def predict_message(message, maxlen=100):\n",
        "    # Загрузка токенизатора и модели\n",
        "    tokenizer = joblib.load('tokenizer.joblib')\n",
        "    model = tf.keras.models.load_model('spam_classification_model.h5')\n",
        "\n",
        "    # Токенизация и паддинг сообщения\n",
        "    message_seq = tokenizer.texts_to_sequences([message])\n",
        "    message_pad = pad_sequences(message_seq, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "    # Прогнозирование\n",
        "    prediction = model.predict(message_pad)[0][0]\n",
        "    return \"Спам\" if prediction > 0.5 else \"Не спам\", prediction\n",
        "\n",
        "def main():\n",
        "    st.title(\"Классификация спам-сообщений\")\n",
        "\n",
        "    # Параметры модели\n",
        "    st.sidebar.header(\"Параметры модели\")\n",
        "    units = st.sidebar.slider(\"Количество LSTM-юнитов\", min_value=16, max_value=256, step=16, value=64)\n",
        "    embedding_dim = st.sidebar.slider(\"Размер вложения\", min_value=16, max_value=256, step=16, value=64)\n",
        "    maxlen = st.sidebar.slider(\"Максимальная длина текста\", min_value=50, max_value=500, step=50, value=100)\n",
        "    epochs = st.sidebar.slider(\"Количество эпох\", min_value=1, max_value=20, step=1, value=5)\n",
        "    batch_size = st.sidebar.slider(\"Размер пакета\", min_value=16, max_value=128, step=16, value=32)\n",
        "\n",
        "    if st.button(\"Запустить обучение\"):\n",
        "        try:\n",
        "            # Загрузка и подготовка данных\n",
        "            X_train, X_test, y_train, y_test = load_and_prepare_data()\n",
        "\n",
        "            # Подготовка последовательностей\n",
        "            X_train_pad, X_test_pad = prepare_sequences(X_train, X_test, maxlen=maxlen)\n",
        "\n",
        "            # Обучение модели\n",
        "            accuracy, fig = train_model(\n",
        "                X_train_pad, y_train,\n",
        "                X_test_pad, y_test,\n",
        "                units=units,\n",
        "                embedding_dim=embedding_dim,\n",
        "                maxlen=maxlen,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "\n",
        "            # Отображение результатов\n",
        "            st.write(f\"Точность на тестовом наборе: {accuracy:.4f}\")\n",
        "            st.pyplot(fig)\n",
        "\n",
        "            st.success(\"Модель успешно обучена и сохранена!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Ошибка при обучении: {str(e)}\")\n",
        "\n",
        "    st.header(\"Проверить сообщение\")\n",
        "    message = st.text_input(\"Введите сообщение для проверки:\")\n",
        "    if st.button(\"Проверить сообщение\"):\n",
        "        if message.strip():\n",
        "            label, confidence = predict_message(message)\n",
        "            st.write(f\"Результат: **{label}** (уверенность: {confidence:.2f})\")\n",
        "        else:\n",
        "            st.error(\"Введите сообщение для проверки!\")\n",
        "\n",
        "# Запуск приложения\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "# Функция для запуска Streamlit\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "# Создаем и запускаем поток для Streamlit\n",
        "streamlit_thread = threading.Thread(target=run_streamlit)\n",
        "streamlit_thread.start()\n",
        "\n",
        "# Небольшая задержка для запуска Streamlit\n",
        "time.sleep(5)\n",
        "\n",
        "# Настройка ngrok\n",
        "ngrok.set_auth_token('2qET4QwGI2E5GRFX4WK7RYelD2q_6AhGNYrZooZx1skoHFCzj')\n",
        "\n",
        "# Создаем туннель\n",
        "tunnel = ngrok.connect(8501)\n",
        "print(f\"Публичный URL: {tunnel}\")\n",
        "\n",
        "# Ожидание для поддержания туннеля открытым\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    ngrok.kill()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1MTvplQwy7z",
        "outputId": "ee8e80d6-a5b9-44d2-ae62-782b3d4f045f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Публичный URL: NgrokTunnel: \"https://393f-34-23-99-199.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}